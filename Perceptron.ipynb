{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY5QoNHIH6Fp","outputId":"170f574a-b4ab-4141-d217-18e5fd30ea71"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import pandas as pd\n","import math\n","from collections import Counter\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["file_path_train = '/content/drive/MyDrive/cs5350/hw3/train.csv'\n","file_path_test = '/content/drive/MyDrive/cs5350/hw3/test.csv'\n","attributes_train = []\n","labels_train = []\n","attributes_test = []\n","labels_test = []\n","with open(file_path_train, 'r') as f:\n","    for line in f:\n","        terms = line.strip().split(',')\n","        attr = [float(x) for x in terms[:4]]\n","        label = int(terms[4])\n","        attributes_train.append(attr)\n","        labels_train.append(label)\n","\n","with open(file_path_test, 'r') as f:\n","    for line in f:\n","        terms = line.strip().split(',')\n","        attr = [float(x) for x in terms[:4]]\n","        label = int(terms[4])\n","        attributes_test.append(attr)\n","        labels_test.append(label)"],"metadata":{"id":"ZUMJUhygeAAV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","X_train = np.array(attributes_train, dtype=float)\n","y_train = np.array(labels_train, dtype=int)\n","X_test = np.array(attributes_test, dtype=float)\n","y_test = np.array(labels_test, dtype=int)\n","\n","y_train = np.where(y_train == 0, -1, 1)\n","y_test = np.where(y_test == 0, -1, 1)"],"metadata":{"id":"QYLibtW6Tmv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def standardPerceptron(X_train, y_train, learning_rate=0.1, T=10):\n","    w = np.zeros(X_train.shape[1] + 1, dtype=float)\n","    for epoch in range(T):\n","        indices = np.random.permutation(X_train.shape[0])\n","        for i in indices:\n","            x_i = np.insert(X_train[i], 0, 1).astype(float)\n","            if y_train[i] * np.dot(w, x_i) <= 0:\n","                w += learning_rate * y_train[i] * x_i\n","    return w"],"metadata":{"id":"uJqqS_55T-Vs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def votedPerceptron(X_train, y_train, learning_rate=0.1, T=10):\n","    w = np.zeros(X_train.shape[1] + 1, dtype=float)\n","    weight_vectors = []\n","    counts = []\n","    m = 0\n","\n","    for epoch in range(T):\n","        indices = np.random.permutation(X_train.shape[0])\n","        for i in indices:\n","            x_i = np.insert(X_train[i], 0, 1).astype(float)\n","            if y_train[i] * np.dot(w, x_i) <= 0:\n","                if m > 0:\n","                    counts[-1] += 1\n","                weight_vectors.append(w.copy())\n","                counts.append(1)\n","                m += 1\n","                w += learning_rate * y_train[i] * x_i\n","            else:\n","                if counts:\n","                    counts[-1] += 1\n","    return weight_vectors, counts\n"],"metadata":{"id":"BRqvzxYuUCnJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predictVotedPerceptron(X, weight_vectors, counts):\n","    X_with_bias = np.insert(X, 0, 1, axis=1).astype(float)\n","    predictions = []\n","    for x in X_with_bias:\n","        weighted_sum = sum(count * np.sign(np.dot(w, x)) for w, count in zip(weight_vectors, counts))\n","        predictions.append(np.sign(weighted_sum))\n","    return np.array(predictions)"],"metadata":{"id":"LZV9PcimUHe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def averagePerceptron(X_train, y_train, learning_rate=0.1, T=10):\n","    w = np.zeros(X_train.shape[1] + 1, dtype=float)\n","    a = np.zeros_like(w)\n","\n","    for epoch in range(T):\n","        indices = np.random.permutation(X_train.shape[0])\n","        for i in indices:\n","            x_i = np.insert(X_train[i], 0, 1).astype(float)\n","            if y_train[i] * np.dot(w, x_i) <= 0:\n","                w += learning_rate * y_train[i] * x_i\n","            a += w\n","    return a"],"metadata":{"id":"CbUZF_bXUPat"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","w_standard = standardPerceptron(X_train, y_train, learning_rate=0.1, T=10)\n","\n","X_test_with_bias = np.insert(X_test, 0, 1, axis=1).astype(float)\n","predictions_standard = np.sign(np.dot(X_test_with_bias, w_standard))\n","accuracy_standard = accuracy_score(y_test, np.where(predictions_standard == -1, 0, 1))\n","\n","average_error_standard = 1 - accuracy_standard\n","print(\"Standard learned weight vector:\", w_standard[1:])\n","print(\"Average prediction error Standard Perceptron:\", average_error_standard)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-H8kf3FRUSHn","outputId":"75498f3f-d5a5-471c-90e9-3903c4ce408e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Standard learned weight vector: [-6.030707  -3.843418  -3.6166041 -1.1041335]\n","Average prediction error Standard Perceptron: 0.5660000000000001\n"]}]},{"cell_type":"code","source":["weight_vectors, counts = votedPerceptron(X_train, y_train, learning_rate=0.1, T=10)\n","\n","print(\"Voted weight vectors and counts:\")\n","for i, (w, c) in enumerate(zip(weight_vectors, counts)):\n","    print(f\"Weight vector {i}: {w}, Count: {c}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vd1gu3gqW7qC","outputId":"7943c9f2-1c2f-44fb-dcb4-0ba9b759dbfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Voted weight vectors and counts:\n","Weight vector 0: [0. 0. 0. 0. 0.], Count: 2\n","Weight vector 1: [ 0.1      -0.36012  -0.65389   1.05234  -0.048967], Count: 3\n","Weight vector 2: [ 0.2      -0.54227  -0.37868   0.980079 -0.284267], Count: 3\n","Weight vector 3: [ 0.3      -0.452758  0.0987    0.495769 -0.843357], Count: 2\n","Weight vector 4: [ 0.2      -0.436076 -0.49104   0.44593  -0.773313], Count: 11\n","Weight vector 5: [ 0.1      -0.366504 -1.35269   0.26174  -0.340423], Count: 4\n","Weight vector 6: [ 2.77555756e-17 -6.54204000e-01 -9.46700000e-01 -1.00850000e-01\n"," -3.07879000e-01], Count: 17\n","Weight vector 7: [ 0.1      -0.503434 -0.75074  -0.40669  -0.320122], Count: 12\n","Weight vector 8: [ 2.77555756e-17 -9.68434000e-01 -2.67770000e-01 -7.52220000e-01\n"," -2.94948000e-01], Count: 6\n","Weight vector 9: [-0.1      -0.993469 -1.20039  -0.38349   0.330482], Count: 14\n","Weight vector 10: [ 2.77555756e-17 -9.37237000e-01 -1.10024000e+00 -6.10750000e-01\n","  3.29877140e-01], Count: 4\n","Weight vector 11: [ 0.1        -1.142527   -0.71639    -0.690294    0.20849714], Count: 4\n","Weight vector 12: [ 0.2        -1.254407   -0.38282    -0.824844    0.01276714], Count: 9\n","Weight vector 13: [ 0.3        -1.455067   -1.05472     0.076776    0.02276564], Count: 9\n","Weight vector 14: [ 0.4        -1.443475   -0.73253    -0.266244   -0.26180436], Count: 7\n","Weight vector 15: [ 0.5        -1.389539   -0.34309    -0.747904   -0.69598436], Count: 6\n","Weight vector 16: [ 0.6        -1.459418   -0.6808     -0.335794   -0.54555436], Count: 13\n","Weight vector 17: [ 0.7        -1.324238   -0.57485    -0.570164   -0.50555636], Count: 3\n","Weight vector 18: [ 0.6        -1.376185   -0.24852    -0.879114   -0.40706436], Count: 5\n","Weight vector 19: [ 0.5        -1.433646   -1.25957    -0.709944    0.03215564], Count: 17\n","Weight vector 20: [ 0.4        -1.615806   -0.61209    -1.515084    0.07401064], Count: 25\n","Weight vector 21: [ 0.5        -1.754676   -1.09982    -0.867344    0.10818964], Count: 7\n","Weight vector 22: [ 0.6        -1.605716   -0.75694    -1.270434   -0.03440036], Count: 3\n","Weight vector 23: [ 0.7        -1.902436   -2.08563     0.076836   -0.29711036], Count: 7\n","Weight vector 24: [ 0.6        -1.935356   -1.64011    -0.380344   -0.19823036], Count: 4\n","Weight vector 25: [ 0.7        -2.551676   -0.76915    -0.401965   -0.56168036], Count: 12\n","Weight vector 26: [ 0.8        -2.454968   -0.38489    -0.895105   -0.97491036], Count: 31\n","Weight vector 27: [ 0.7        -2.215138   -1.64549    -1.189745   -0.39603036], Count: 42\n","Weight vector 28: [ 0.8        -2.297739   -1.34938    -1.318385   -0.54250036], Count: 7\n","Weight vector 29: [ 0.9        -2.058569   -0.89373    -1.817265   -0.83237036], Count: 49\n","Weight vector 30: [ 0.8        -1.788679   -2.11357    -1.884926    0.02244964], Count: 5\n","Weight vector 31: [ 0.9        -1.917139   -1.78642    -2.061636   -0.30363036], Count: 3\n","Weight vector 32: [ 1.         -2.042819   -1.93375    -1.774456   -0.25897736], Count: 67\n","Weight vector 33: [ 1.1        -2.331109   -1.54411    -1.793336   -0.37569736], Count: 13\n","Weight vector 34: [ 1.2        -2.163119   -1.12343    -2.247316   -0.61500736], Count: 2\n","Weight vector 35: [ 1.3        -2.391719   -1.66827    -1.666926   -0.52677636], Count: 50\n","Weight vector 36: [ 1.2        -2.443669   -1.34194    -1.975876   -0.42828636], Count: 4\n","Weight vector 37: [ 1.3        -2.929209   -1.93231    -0.877696   -0.51048536], Count: 40\n","Weight vector 38: [ 1.4        -2.855449   -1.44706    -1.357556   -1.07707536], Count: 15\n","Weight vector 39: [ 1.3        -2.790977   -0.98644    -2.192256   -0.80608536], Count: 12\n","Weight vector 40: [ 1.4        -2.971737   -1.86775    -1.321396   -0.82776736], Count: 16\n","Weight vector 41: [ 1.5        -2.812697   -1.64654    -1.633226   -0.83949236], Count: 6\n","Weight vector 42: [ 1.4        -2.734007   -2.60317    -1.254556   -0.08915236], Count: 5\n","Weight vector 43: [ 1.5        -2.704487   -2.11461    -1.769456   -0.71238236], Count: 96\n","Weight vector 44: [ 1.4        -2.756437   -1.78828    -2.078406   -0.61389236], Count: 113\n","Weight vector 45: [ 1.5        -2.700498   -1.81932    -2.060099   -0.56923936], Count: 3\n","Weight vector 46: [ 1.6        -2.984408   -2.48232    -1.011609   -0.61135236], Count: 17\n","Weight vector 47: [ 1.7        -3.085528   -2.18248    -1.128249   -0.77320236], Count: 39\n","Weight vector 48: [ 1.8        -2.984358   -2.09226    -1.363309   -0.73048836], Count: 6\n","Weight vector 49: [ 1.7        -3.017282   -1.64674    -1.820489   -0.63160836], Count: 24\n","Weight vector 50: [ 1.6        -3.069232   -1.32041    -2.129439   -0.53311836], Count: 8\n","Weight vector 51: [ 1.7        -2.867462   -1.14059    -2.425249   -0.51212836], Count: 12\n","Weight vector 52: [ 1.8        -2.93347    -1.46319    -2.044669   -0.39376836], Count: 3\n","Weight vector 53: [ 1.9        -2.71404    -1.00816    -2.542269   -0.66630836], Count: 20\n","Weight vector 54: [ 1.8        -2.701416   -2.04032    -2.171059   -0.05445836], Count: 36\n","Weight vector 55: [ 1.9        -2.498316   -1.85512    -2.472269   -0.05415806], Count: 5\n","Weight vector 56: [ 2.         -2.961696   -3.13021    -0.800609   -0.37583806], Count: 12\n","Weight vector 57: [ 2.1        -3.04953    -2.80451    -1.168389   -0.70527806], Count: 3\n","Weight vector 58: [ 2.         -3.26569    -2.11647    -1.983559   -0.69717326], Count: 2\n","Weight vector 59: [ 2.1        -3.13051    -2.01052    -2.217929   -0.65717526], Count: 46\n","Weight vector 60: [ 2.         -3.182457   -1.68419    -2.526879   -0.55868326], Count: 6\n","Weight vector 61: [ 2.1        -3.436187   -2.38009    -1.646339   -0.40579326], Count: 28\n","Weight vector 62: [ 2.2        -3.314207   -2.17027    -1.965879   -0.39295026], Count: 12\n","Weight vector 63: [ 2.3        -3.135457   -1.69227    -2.479499   -0.71657026], Count: 73\n","Weight vector 64: [ 2.4        -3.336117   -2.36417    -1.577879   -0.70657176], Count: 36\n","Weight vector 65: [ 2.5        -3.187157   -2.02129    -1.980969   -0.84916176], Count: 37\n","Weight vector 66: [ 2.6        -3.028117   -1.80008    -2.292799   -0.86088676], Count: 7\n","Weight vector 67: [ 2.5        -2.949427   -2.75671    -1.914129   -0.11054676], Count: 6\n","Weight vector 68: [ 2.6        -3.061307   -2.42314    -2.048679   -0.30627676], Count: 37\n","Weight vector 69: [ 2.5        -3.113257   -2.09681    -2.357629   -0.20778676], Count: 4\n","Weight vector 70: [ 2.4        -3.146181   -1.65129    -2.814809   -0.10890676], Count: 33\n","Weight vector 71: [ 2.5        -3.454841   -2.31491    -1.760759   -0.19808876], Count: 46\n","Weight vector 72: [ 2.6        -3.296741   -2.228001   -1.992139   -0.11567676], Count: 40\n","Weight vector 73: [ 2.7        -3.151731   -1.867331   -2.397709   -0.27533676], Count: 36\n","Weight vector 74: [ 2.6        -3.203681   -1.541001   -2.706659   -0.17684676], Count: 31\n","Weight vector 75: [ 2.7        -3.429851   -2.015281   -2.071769   -0.16568476], Count: 26\n","Weight vector 76: [ 2.8        -3.279081   -1.819321   -2.377609   -0.17792776], Count: 3\n","Weight vector 77: [ 2.9        -3.606001   -3.093381   -0.821879   -0.19210976], Count: 10\n","Weight vector 78: [ 3.         -3.69541    -2.773471   -1.004069   -0.48662976], Count: 53\n","Weight vector 79: [ 2.9        -3.90463    -2.092471   -1.850429   -0.42641376], Count: 6\n","Weight vector 80: [ 3.         -3.78383    -1.685031   -2.326779   -0.68770376], Count: 3\n","Weight vector 81: [ 2.9        -3.70514    -2.641661   -1.948109    0.06263624], Count: 133\n","Weight vector 82: [ 3.         -3.63696    -2.156621   -2.469439   -0.54779376], Count: 43\n","Weight vector 83: [ 3.1        -3.43519    -1.976801   -2.765249   -0.52680376], Count: 4\n","Weight vector 84: [ 3.2        -3.79504    -3.342731   -1.004729   -0.77607376], Count: 9\n","Weight vector 85: [ 3.3        -3.68867    -2.973161   -1.420669   -0.96986376], Count: 2\n","Weight vector 86: [ 3.4        -3.599158   -2.495781   -1.904979   -1.52895376], Count: 43\n","Weight vector 87: [ 3.5        -3.379728   -2.040751   -2.402579   -1.80149376], Count: 7\n","Weight vector 88: [ 3.4        -3.431678   -1.714421   -2.711529   -1.70300376], Count: 42\n","Weight vector 89: [ 3.3        -3.459129   -2.636281   -2.382899   -1.21852376], Count: 17\n","Weight vector 90: [ 3.2        -3.394657   -2.175661   -3.217599   -0.94753376], Count: 3\n","Weight vector 91: [ 3.3        -3.595317   -2.847561   -2.315979   -0.93753526], Count: 78\n","Weight vector 92: [ 3.4        -3.437217   -2.760652   -2.547359   -0.85512326], Count: 23\n","Weight vector 93: [ 3.3        -3.489167   -2.434322   -2.856309   -0.75663326], Count: 4\n","Weight vector 94: [ 3.2        -3.541117   -2.107992   -3.165259   -0.65814326], Count: 18\n","Weight vector 95: [ 3.3        -3.900967   -3.473922   -1.404739   -0.90741326], Count: 27\n","Weight vector 96: [ 3.2        -4.172577   -3.053862   -1.823879   -0.92439426], Count: 41\n","Weight vector 97: [ 3.1        -4.381797   -2.372862   -2.670239   -0.86417826], Count: 9\n","Weight vector 98: [ 3.         -4.414721   -1.927342   -3.127419   -0.76529826], Count: 35\n","Weight vector 99: [ 3.1        -4.554401   -2.894322   -2.180899   -0.80017026], Count: 36\n","Weight vector 100: [ 3.2        -4.409391   -2.533652   -2.586469   -0.95983026], Count: 43\n","Weight vector 101: [ 3.1        -4.461338   -2.207322   -2.895419   -0.86133826], Count: 16\n","Weight vector 102: [ 3.         -4.196548   -3.221062   -2.762319   -0.31426826], Count: 11\n","Weight vector 103: [ 3.1        -4.075748   -2.813622   -3.238669   -0.57555826], Count: 10\n","Weight vector 104: [ 3.2        -4.398798   -3.534972   -2.074339   -0.67017126], Count: 114\n","Weight vector 105: [ 3.3        -4.195698   -3.349772   -2.375549   -0.66987096], Count: 27\n","Weight vector 106: [ 3.4        -4.044928   -3.153812   -2.681389   -0.68211396], Count: 87\n","Weight vector 107: [ 3.5        -3.938558   -2.784242   -3.097329   -0.87590396], Count: 17\n","Weight vector 108: [ 3.6        -3.699388   -2.328592   -3.596209   -1.16577396], Count: 103\n","Weight vector 109: [ 3.7        -3.983298   -2.991592   -2.547719   -1.20788696], Count: 10\n","Weight vector 110: [ 3.6        -4.016218   -2.546072   -3.004899   -1.10900696], Count: 6\n","Weight vector 111: [ 3.5        -4.068168   -2.219742   -3.313849   -1.01051696], Count: 13\n","Weight vector 112: [ 3.6        -4.382398   -3.523392   -1.746119   -1.07668196], Count: 4\n","Weight vector 113: [ 3.7        -4.247218   -3.417442   -1.980489   -1.03668396], Count: 69\n","Weight vector 114: [ 3.8        -4.157706   -2.940062   -2.464799   -1.59577396], Count: 64\n","Weight vector 115: [ 3.9        -3.955936   -2.760242   -2.760609   -1.57478396], Count: 8\n","Weight vector 116: [ 3.8        -3.877246   -3.716872   -2.381939   -0.82444396], Count: 4\n","Weight vector 117: [ 3.7        -3.861138   -3.070632   -3.217669   -0.67228396], Count: 8\n","Weight vector 118: [ 3.8        -3.658038   -2.885432   -3.518879   -0.67198366], Count: 2\n","Weight vector 119: [ 3.9        -4.017888   -4.251362   -1.758359   -0.92125366], Count: 141\n","Weight vector 120: [ 4.         -3.988368   -3.762802   -2.273259   -1.54448366], Count: 55\n","Weight vector 121: [ 3.9        -4.133158   -3.274862   -3.107539   -1.33362366], Count: 96\n","Weight vector 122: [ 4.         -3.913728   -2.819832   -3.605139   -1.60616366], Count: 62\n","Weight vector 123: [ 4.1        -4.249548   -3.543872   -2.460949   -1.66327666], Count: 135\n","Weight vector 124: [ 4.2        -4.010378   -3.088222   -2.959829   -1.95314666], Count: 6\n","Weight vector 125: [ 4.1        -3.99427    -2.441982   -3.795559   -1.80098666], Count: 9\n","Weight vector 126: [ 4.         -3.72948    -3.455722   -3.662459   -1.25391666], Count: 7\n","Weight vector 127: [ 4.1        -4.01339    -4.118722   -2.613969   -1.29602966], Count: 15\n","Weight vector 128: [ 4.2        -3.88156    -3.928552   -2.945079   -1.28952256], Count: 18\n","Weight vector 129: [ 4.3        -3.72252    -3.707342   -3.256909   -1.30124756], Count: 78\n","Weight vector 130: [ 4.2        -3.81549    -3.327632   -3.721199   -1.27167756], Count: 5\n","Weight vector 131: [ 4.1        -3.86744    -3.001302   -4.030149   -1.17318756], Count: 8\n","Weight vector 132: [ 4.2        -4.21804    -4.257972   -2.514089   -1.24840356], Count: 21\n","Weight vector 133: [ 4.1        -4.26999    -3.931642   -2.823039   -1.14991356], Count: 32\n","Weight vector 134: [ 4.         -4.32194    -3.605312   -3.131989   -1.05142356], Count: 2\n","Weight vector 135: [ 3.9        -4.373887   -3.278982   -3.440939   -0.95293156], Count: 36\n","Weight vector 136: [ 3.8        -4.406811   -2.833462   -3.898119   -0.85405156], Count: 3\n","Weight vector 137: [ 3.9        -4.607471   -3.505362   -2.996499   -0.84405306], Count: 53\n","Weight vector 138: [ 4.         -4.462461   -3.144692   -3.402069   -1.00371306], Count: 13\n","Weight vector 139: [ 3.9        -4.495381   -2.699172   -3.859249   -0.90483306], Count: 134\n","Weight vector 140: [ 4.         -4.56526    -3.036882   -3.447139   -0.75440306], Count: 15\n","Weight vector 141: [ 3.9        -4.598184   -2.591362   -3.904319   -0.65552306], Count: 64\n","Weight vector 142: [ 4.         -4.737864   -3.558342   -2.957799   -0.69039506], Count: 25\n","Weight vector 143: [ 3.9        -4.770784   -3.112822   -3.414979   -0.59151506], Count: 58\n","Weight vector 144: [ 3.8        -4.822731   -2.786492   -3.723929   -0.49302306], Count: 22\n","Weight vector 145: [ 3.9        -5.204761   -4.092002   -2.028099   -0.72354306], Count: 7\n","Weight vector 146: [ 4.         -5.287362   -3.795892   -2.156739   -0.87001306], Count: 44\n","Weight vector 147: [ 3.9        -5.271254   -3.149652   -2.992469   -0.71785306], Count: 14\n","Weight vector 148: [ 4.         -5.092504   -2.671652   -3.506089   -1.04147306], Count: 122\n","Weight vector 149: [ 3.9        -4.827714   -3.685392   -3.372989   -0.49440306], Count: 28\n","Weight vector 150: [ 4.         -4.608284   -3.230362   -3.870589   -0.76694306], Count: 24\n","Weight vector 151: [ 3.9        -4.660234   -2.904032   -4.179539   -0.66845306], Count: 34\n","Weight vector 152: [ 4.         -4.983284   -3.625382   -3.015209   -0.76306606], Count: 97\n","Weight vector 153: [ 3.9        -5.035234   -3.299052   -3.324159   -0.66457606], Count: 112\n","Weight vector 154: [ 4.         -4.796064   -2.843402   -3.823039   -0.95444606], Count: 47\n","Weight vector 155: [ 4.1        -5.233794   -3.395072   -2.729139   -0.99526606], Count: 20\n","Weight vector 156: [ 4.2        -5.032024   -3.215252   -3.024949   -0.97427606], Count: 19\n","Weight vector 157: [ 4.3        -4.872984   -2.994042   -3.336779   -0.98600106], Count: 58\n","Weight vector 158: [ 4.4        -4.669884   -2.808842   -3.637989   -0.98570076], Count: 15\n","Weight vector 159: [ 4.5        -4.996804   -4.082902   -2.082259   -0.99988276], Count: 4\n","Weight vector 160: [ 4.4        -5.186474   -3.831272   -2.363189   -0.92014076], Count: 84\n","Weight vector 161: [ 4.5        -5.065674   -3.423832   -2.839539   -1.18143076], Count: 88\n","Weight vector 162: [ 4.6        -4.920664   -3.063162   -3.245109   -1.34109076], Count: 73\n","Weight vector 163: [ 4.5        -4.972614   -2.736832   -3.554059   -1.24260076], Count: 20\n","Weight vector 164: [ 4.4        -4.842614   -3.763612   -3.258759   -0.65622076], Count: 6\n","Weight vector 165: [ 4.3        -4.894561   -3.437282   -3.567709   -0.55772876], Count: 9\n","Weight vector 166: [ 4.4        -4.715811   -2.959282   -4.081329   -0.88134876], Count: 24\n","Weight vector 167: [ 4.5        -5.030041   -4.262932   -2.513599   -0.94751376], Count: 43\n","Weight vector 168: [ 4.6        -4.826941   -4.077732   -2.814809   -0.94721346], Count: 107\n","Weight vector 169: [ 4.7        -4.676171   -3.881772   -3.120649   -0.95945646], Count: 15\n","Weight vector 170: [ 4.6        -4.709095   -3.436252   -3.577829   -0.86057646], Count: 25\n","Weight vector 171: [ 4.7        -4.469925   -2.980602   -4.076709   -1.15044646], Count: 4\n","Weight vector 172: [ 4.6        -4.521875   -2.654272   -4.385659   -1.05195646], Count: 84\n","Weight vector 173: [ 4.7        -4.923605   -3.485502   -3.140189   -1.19570646], Count: 32\n","Weight vector 174: [ 4.8        -4.704175   -3.030472   -3.637789   -1.46824646], Count: 20\n","Weight vector 175: [ 4.7        -4.737095   -2.584952   -4.094969   -1.36936646], Count: 39\n","Weight vector 176: [ 4.8        -5.096255   -3.207802   -3.071079   -1.48479646], Count: 109\n","Weight vector 177: [ 4.9        -4.894485   -3.027982   -3.366889   -1.46380646], Count: 112\n","Weight vector 178: [ 4.8        -4.946435   -2.701652   -3.675839   -1.36531646], Count: 18\n","Weight vector 179: [ 4.7        -4.760595   -3.490252   -3.509409   -1.18147646], Count: 15\n","Weight vector 180: [ 4.6        -4.812545   -3.163922   -3.818359   -1.08298646], Count: 20\n","Weight vector 181: [ 4.5        -4.845465   -2.718402   -4.275539   -0.98410646], Count: 93\n","Weight vector 182: [ 4.6        -5.099195   -3.414302   -3.394999   -0.83121646], Count: 68\n","Weight vector 183: [ 4.7        -4.954185   -3.053632   -3.800569   -0.99087646], Count: 34\n","Weight vector 184: [ 4.6        -5.006132   -2.727302   -4.109519   -0.89238446], Count: 19\n","Weight vector 185: [ 4.7        -5.145812   -3.694282   -3.162999   -0.92725646], Count: 66\n","Weight vector 186: [ 4.8        -4.972502   -3.298842   -3.637119   -1.17742646], Count: 40\n","Weight vector 187: [ 4.9        -4.770732   -3.119022   -3.932929   -1.15643646], Count: 6\n","Weight vector 188: [ 4.8        -4.692042   -4.075652   -3.554259   -0.40609646], Count: 211\n","Weight vector 189: [ 4.9        -4.543082   -3.732772   -3.957349   -0.54868646], Count: 2\n","Weight vector 190: [ 5.         -4.323652   -3.277742   -4.454949   -0.82122646], Count: 4\n","Weight vector 191: [ 4.9        -4.375602   -2.951412   -4.763899   -0.72273646], Count: 38\n","Weight vector 192: [ 5.         -4.734762   -3.574262   -3.740009   -0.83816646], Count: 29\n","Weight vector 193: [ 4.9        -4.786712   -3.247932   -4.048959   -0.73967646], Count: 41\n","Weight vector 194: [ 5.         -5.109762   -3.969282   -2.884629   -0.83428946], Count: 53\n","Weight vector 195: [ 5.1        -4.987782   -3.759462   -3.204169   -0.82144646], Count: 190\n","Weight vector 196: [ 5.2        -4.748612   -3.303812   -3.703049   -1.11131646], Count: 27\n","Weight vector 197: [ 5.1        -4.800562   -2.977482   -4.011999   -1.01282646], Count: 32\n","Weight vector 198: [ 5.2        -5.084472   -3.640482   -2.963509   -1.05493946], Count: 128\n","Weight vector 199: [ 5.3        -4.925432   -3.419272   -3.275339   -1.06666446], Count: 45\n","Weight vector 200: [ 5.4        -4.686262   -2.963622   -3.774219   -1.35653446], Count: 16\n","Weight vector 201: [ 5.3        -4.556262   -3.990402   -3.478919   -0.77015446], Count: 16\n","Weight vector 202: [ 5.4        -4.353162   -3.805202   -3.780129   -0.76985416], Count: 16\n","Weight vector 203: [ 5.3        -4.386082   -3.359682   -4.237309   -0.67097416], Count: 16\n","Weight vector 204: [ 5.4        -4.709132   -4.081032   -3.072979   -0.76558716], Count: 31\n","Weight vector 205: [ 5.3        -4.761079   -3.754702   -3.381929   -0.66709516], Count: 38\n","Weight vector 206: [ 5.2        -4.744971   -3.108462   -4.217659   -0.51493516], Count: 61\n","Weight vector 207: [ 5.3        -5.147151   -3.938862   -2.962159   -0.66592516], Count: 233\n","Weight vector 208: [ 5.2        -5.199101   -3.612532   -3.271109   -0.56743516], Count: 49\n","Weight vector 209: [ 5.3        -4.997331   -3.432712   -3.566919   -0.54644516], Count: 16\n","Weight vector 210: [ 5.4        -4.777901   -2.977682   -4.064519   -0.81898516], Count: 16\n","Weight vector 211: [ 5.5        -5.215631   -3.529352   -2.970619   -0.85980516], Count: 61\n","Weight vector 212: [ 5.4        -5.248555   -3.083832   -3.427799   -0.76092516], Count: 41\n","Weight vector 213: [ 5.3        -5.300505   -2.757502   -3.736749   -0.66243516], Count: 7\n","Weight vector 214: [ 5.4        -5.614735   -4.061152   -2.169019   -0.72860016], Count: 29\n","Weight vector 215: [ 5.5        -5.395305   -3.606122   -2.666619   -1.00114016], Count: 22\n","Weight vector 216: [ 5.4        -5.447255   -3.279792   -2.975569   -0.90265016], Count: 58\n","Weight vector 217: [ 5.5        -5.245485   -3.099972   -3.271379   -0.88166016], Count: 112\n","Weight vector 218: [ 5.6        -5.006315   -2.644322   -3.770259   -1.17153016], Count: 6\n","Weight vector 219: [ 5.5        -5.058262   -2.317992   -4.079209   -1.07303816], Count: 24\n","Weight vector 220: [ 5.6        -5.342172   -2.980992   -3.030719   -1.11515116], Count: 25\n","Weight vector 221: [ 5.7        -5.139072   -2.795792   -3.331929   -1.11485086], Count: 86\n","Weight vector 222: [ 5.6        -4.953232   -3.584392   -3.165499   -0.93101086], Count: 33\n","Weight vector 223: [ 5.7        -4.794192   -3.363182   -3.477329   -0.94273586], Count: 32\n","Weight vector 224: [ 5.6        -4.846142   -3.036852   -3.786279   -0.84424586], Count: 6\n","Weight vector 225: [ 5.5        -4.879062   -2.591332   -4.243459   -0.74536586], Count: 29\n","Weight vector 226: [ 5.6        -5.217902   -3.412832   -3.210309   -0.64717886], Count: 287\n","Weight vector 227: [ 5.7        -5.049912   -2.992152   -3.664289   -0.88648886], Count: 2\n","Weight vector 228: [ 5.6        -4.971222   -3.948782   -3.285619   -0.13614886], Count: 8\n","Weight vector 229: [ 5.5        -5.023172   -3.622452   -3.594569   -0.03765886], Count: 116\n","Weight vector 230: [ 5.6        -4.878162   -3.261782   -4.000139   -0.19731886], Count: 51\n","Weight vector 231: [ 5.7        -5.253192   -4.607642   -2.240819   -0.47502886], Count: 4\n","Weight vector 232: [ 5.6        -5.580162   -4.173502   -2.609659   -0.44519986], Count: 67\n","Weight vector 233: [ 5.7        -5.483454   -3.789242   -3.102799   -0.85842986], Count: 47\n","Weight vector 234: [ 5.8        -5.244284   -3.333592   -3.601679   -1.14829986], Count: 66\n","Weight vector 235: [ 5.7        -5.296231   -3.007262   -3.910629   -1.04980786], Count: 7\n","Weight vector 236: [ 5.8        -5.656081   -4.373192   -2.150109   -1.29907786], Count: 4\n","Weight vector 237: [ 5.9        -5.530361   -3.885882   -2.678719   -1.88648786], Count: 14\n","Weight vector 238: [ 5.8        -5.623331   -3.506172   -3.143009   -1.85691786], Count: 26\n","Weight vector 239: [ 5.9        -5.464291   -3.284962   -3.454839   -1.86864286], Count: 25\n","Weight vector 240: [ 6.         -5.262521   -3.105142   -3.750649   -1.84765286], Count: 29\n","Weight vector 241: [ 5.9        -5.132521   -4.131922   -3.455349   -1.26127286], Count: 137\n","Weight vector 242: [ 5.8        -5.165441   -3.686402   -3.912529   -1.16239286], Count: 49\n","Weight vector 243: [ 5.7        -5.198365   -3.240882   -4.369709   -1.06351286], Count: 9\n","Weight vector 244: [ 5.8        -5.525285   -4.514942   -2.813979   -1.07769486], Count: 9\n","Weight vector 245: [ 5.7        -5.707445   -3.867462   -3.619119   -1.03583986], Count: 137\n","Weight vector 246: [ 5.6        -5.759395   -3.541132   -3.928069   -0.93734986], Count: 93\n","Weight vector 247: [ 5.5        -5.811345   -3.214802   -4.237019   -0.83885986], Count: 29\n","Weight vector 248: [ 5.6        -6.186375   -4.560662   -2.477699   -1.11656986], Count: 39\n","Weight vector 249: [ 5.7        -6.080005   -4.191092   -2.893639   -1.31035986], Count: 49\n","Weight vector 250: [ 5.6        -6.131955   -3.864762   -3.202589   -1.21186986], Count: 9\n","Weight vector 251: [ 5.7        -5.982995   -3.521882   -3.605679   -1.35445986], Count: 4\n"]}]},{"cell_type":"code","source":["predictions_voted = predictVotedPerceptron(X_test, weight_vectors, counts)\n","accuracy_voted = accuracy_score(y_test, np.where(predictions_voted == -1, 0, 1))\n","\n","average_error_voted = 1 - accuracy_voted\n","print(\"Average prediction error Voted Perceptron:\", average_error_voted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwzjpqV7g_y1","outputId":"32860f83-f273-4c08-da4c-995f6427d85b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average prediction error Voted Perceptron: 0.5660000000000001\n"]}]},{"cell_type":"code","source":["w_average = averagePerceptron(X_train, y_train, learning_rate=0.1, T=10)\n","\n","predictions_average = np.sign(np.dot(X_test_with_bias, w_average))\n","accuracy_average = accuracy_score(y_test, np.where(predictions_average == -1, 0, 1))\n","\n","average_error_average = 1 - accuracy_average\n","print(\"Average learned weight vector:\", w_average[1:])\n","print(\"Average prediction error Average Perceptron:\", average_error_average)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tujP9EbMXRnU","outputId":"0701e62d-1852-4a67-84ca-dc68ccf46fd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average learned weight vector: [-41926.9927537 -25914.283657  -26762.4355355  -7394.6339682]\n","Average prediction error Average Perceptron: 0.5640000000000001\n"]}]},{"cell_type":"markdown","source":["2c) When comparing the list of weight vectors from voted perceptron to the average perceptron learned weight vector, they are extremely different and even magnitudes apart. It is possible that there was a lot of noise or variablity in the data."],"metadata":{"id":"2QlHTl3bkdoF"}},{"cell_type":"markdown","source":["2d) When comparing the three perceptron methods, the predicted errors were very similar. The average has the lowest and standard has the highest. This is probably due to the fact standard relys on one weight vector and average takes the average weight."],"metadata":{"id":"843TpKdOlZGy"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}