{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21451,"status":"ok","timestamp":1734225667782,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"},"user_tz":420},"id":"ql_JqSsCSvqY","outputId":"cf2a7cec-c0cf-4afb-916c-ec6caaf384ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import pandas as pd\n","import math\n","from collections import Counter\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":827,"status":"ok","timestamp":1734225685040,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"},"user_tz":420},"id":"xpWzg9DdTSWg"},"outputs":[],"source":["file_path_train = '/content/drive/MyDrive/cs5350/hw5/train.csv'\n","file_path_test = '/content/drive/MyDrive/cs5350/hw5/test.csv'\n","attributes_train = []\n","labels_train = []\n","attributes_test = []\n","labels_test = []\n","with open(file_path_train, 'r') as f:\n","    for line in f:\n","        terms = line.strip().split(',')\n","        attr = [float(x) for x in terms[:4]]\n","        label = int(terms[4])\n","        attributes_train.append(attr)\n","        labels_train.append(label)\n","\n","with open(file_path_test, 'r') as f:\n","    for line in f:\n","        terms = line.strip().split(',')\n","        attr = [float(x) for x in terms[:4]]\n","        label = int(terms[4])\n","        attributes_test.append(attr)\n","        labels_test.append(label)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":84,"status":"ok","timestamp":1734225688727,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"},"user_tz":420},"id":"NN-yDPAATW3b"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","X_train = np.array(attributes_train, dtype=float)\n","y_train = np.array(labels_train, dtype=int)\n","X_test = np.array(attributes_test, dtype=float)\n","y_test = np.array(labels_test, dtype=int)\n","\n","y_train = np.where(y_train == 0, -1, 1)\n","y_test = np.where(y_test == 0, -1, 1)"]},{"cell_type":"markdown","source":["a)"],"metadata":{"id":"RwBR0f9QA6f3"}},{"cell_type":"code","source":["import numpy as np\n","def sigmoid(z):\n","    return 1.0 / (1.0 + np.exp(-z))"],"metadata":{"id":"tKTPD2nZA_qH","executionInfo":{"status":"ok","timestamp":1734227621108,"user_tz":420,"elapsed":79,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def sigmoid_prime(z):\n","    s = sigmoid(z)\n","    return s * (1 - s)"],"metadata":{"id":"mkHC7bhcBER7","executionInfo":{"status":"ok","timestamp":1734227622427,"user_tz":420,"elapsed":58,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class ThreeLayerNetwork:\n","    def __init__(self):\n","        #Layer 1\n","        self.w1_01 = -1.0\n","        self.w1_11 = -2.0\n","        self.w1_21 = -3.0\n","        self.w1_02 = 1.0\n","        self.w1_12 = 2.0\n","        self.w1_22 = 3.0\n","\n","        #2\n","        self.w2_01 = -1.0\n","        self.w2_11 = -2.0\n","        self.w2_21 = -3.0\n","        self.w2_02 = 1.0\n","        self.w2_12 = 2.0\n","        self.w2_22 = 3.0\n","\n","        #3\n","        self.w3_01 = -1.0\n","        self.w3_11 = 2.0\n","        self.w3_21 = -1.5\n","\n","    def forward(self, x1, x2):\n","        x0 = 1.0\n","        #1st hidden layer\n","        a1_1 = self.w1_01*x0 + self.w1_11*x1 + self.w1_21*x2\n","        a1_2 = self.w1_02*x0 + self.w1_12*x1 + self.w1_22*x2\n","        z1_1 = sigmoid(a1_1)\n","        z1_2 = sigmoid(a1_2)\n","        z1_0 = 1.0\n","\n","        #2nd\n","        a2_1 = self.w2_01*z1_0 + self.w2_11*z1_1 + self.w2_21*z1_2\n","        a2_2 = self.w2_02*z1_0 + self.w2_12*z1_1 + self.w2_22*z1_2\n","        z2_1 = sigmoid(a2_1)\n","        z2_2 = sigmoid(a2_2)\n","        z2_0 = 1.0\n","\n","        #Output\n","        a3_1 = self.w3_01*z2_0 + self.w3_11*z2_1 + self.w3_21*z2_2\n","        y = sigmoid(a3_1)\n","\n","        cache = {\n","            'x0': x0, 'x1': x1, 'x2': x2,\n","            'a1_1': a1_1, 'a1_2': a1_2,\n","            'z1_0': z1_0, 'z1_1': z1_1, 'z1_2': z1_2,\n","            'a2_1': a2_1, 'a2_2': a2_2,\n","            'z2_0': z2_0, 'z2_1': z2_1, 'z2_2': z2_2,\n","            'a3_1': a3_1, 'y': y\n","        }\n","        return y, cache\n","\n","    def backward(self, cache, y_true):\n","        y = cache['y']\n","        dL_dy = (y - y_true)\n","        dL_da3_1 = dL_dy * sigmoid_prime(cache['a3_1'])\n","\n","        z2_0, z2_1, z2_2 = cache['z2_0'], cache['z2_1'], cache['z2_2']\n","        dL_dw3_01 = dL_da3_1 * z2_0\n","        dL_dw3_11 = dL_da3_1 * z2_1\n","        dL_dw3_21 = dL_da3_1 * z2_2\n","\n","        dL_dz2_1 = dL_da3_1 * self.w3_11\n","        dL_dz2_2 = dL_da3_1 * self.w3_21\n","\n","        da2_1 = sigmoid_prime(cache['a2_1'])\n","        da2_2 = sigmoid_prime(cache['a2_2'])\n","\n","        dL_da2_1 = dL_dz2_1 * da2_1\n","        dL_da2_2 = dL_dz2_2 * da2_2\n","\n","        z1_0, z1_1, z1_2 = cache['z1_0'], cache['z1_1'], cache['z1_2']\n","        dL_dw2_01 = dL_da2_1 * z1_0\n","        dL_dw2_11 = dL_da2_1 * z1_1\n","        dL_dw2_21 = dL_da2_1 * z1_2\n","\n","        dL_dw2_02 = dL_da2_2 * z1_0\n","        dL_dw2_12 = dL_da2_2 * z1_1\n","        dL_dw2_22 = dL_da2_2 * z1_2\n","\n","        dL_dz1_1 = dL_da2_1*self.w2_11 + dL_da2_2*self.w2_12\n","        dL_dz1_2 = dL_da2_1*self.w2_21 + dL_da2_2*self.w2_22\n","\n","        da1_1 = sigmoid_prime(cache['a1_1'])\n","        da1_2 = sigmoid_prime(cache['a1_2'])\n","\n","        dL_da1_1 = dL_dz1_1 * da1_1\n","        dL_da1_2 = dL_dz1_2 * da1_2\n","\n","        x0, x1, x2 = cache['x0'], cache['x1'], cache['x2']\n","        dL_dw1_01 = dL_da1_1 * x0\n","        dL_dw1_11 = dL_da1_1 * x1\n","        dL_dw1_21 = dL_da1_1 * x2\n","\n","        dL_dw1_02 = dL_da1_2 * x0\n","        dL_dw1_12 = dL_da1_2 * x1\n","        dL_dw1_22 = dL_da1_2 * x2\n","\n","        grads = {\n","            'w3_01': dL_dw3_01, 'w3_11': dL_dw3_11, 'w3_21': dL_dw3_21,\n","            'w2_01': dL_dw2_01, 'w2_11': dL_dw2_11, 'w2_21': dL_dw2_21,\n","            'w2_02': dL_dw2_02, 'w2_12': dL_dw2_12, 'w2_22': dL_dw2_22,\n","            'w1_01': dL_dw1_01, 'w1_11': dL_dw1_11, 'w1_21': dL_dw1_21,\n","            'w1_02': dL_dw1_02, 'w1_12': dL_dw1_12, 'w1_22': dL_dw1_22\n","        }\n","        return grads\n","\n","net = ThreeLayerNetwork()\n","x1, x2 = 1.0, 1.0\n","y_true = 1.0\n","\n","y_pred, cache = net.forward(x1, x2)\n","print(\"Output y:\", y_pred)\n","\n","grads = net.backward(cache, y_true)\n","print(\"Gradients:\")\n","for k, v in grads.items():\n","    print(k, v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"snPUmNPy8ZLq","executionInfo":{"status":"ok","timestamp":1734227629521,"user_tz":420,"elapsed":77,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"babdd5a5-e364-44cf-f590-cd8aa5b8b806"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Output y: 0.08040217301208424\n","Gradients:\n","w3_01 -0.06799291476718632\n","w3_11 -0.0012259078520512152\n","w3_21 -0.06676700691513511\n","w2_01 -0.0024076096256642077\n","w2_11 -5.9531113125541e-06\n","w2_21 -0.002401656514351654\n","w2_02 0.001805707219248146\n","w2_12 4.464833484415552e-06\n","w2_22 0.0018012423857637306\n","w1_01 2.0784370290840247e-05\n","w1_11 2.0784370290840247e-05\n","w1_21 2.0784370290840247e-05\n","w1_02 3.117655543625889e-05\n","w1_12 3.117655543625889e-05\n","w1_22 3.117655543625889e-05\n"]}]},{"cell_type":"code","source":["net = ThreeLayerNetwork()\n","x1, x2 = 1.0, 1.0\n","y_true = 1.0\n","\n","y_pred, cache = net.forward(x1, x2)\n","print(\"Output y:\", y_pred)\n","\n","grads = net.backward(cache, y_true)\n","print(\"Gradients:\")\n","for k, v in grads.items():\n","    print(k, v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQFCGCGTBOA5","executionInfo":{"status":"ok","timestamp":1734227632068,"user_tz":420,"elapsed":71,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"76baac62-b08b-4233-ddad-278341b322bf"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Output y: 0.08040217301208424\n","Gradients:\n","w3_01 -0.06799291476718632\n","w3_11 -0.0012259078520512152\n","w3_21 -0.06676700691513511\n","w2_01 -0.0024076096256642077\n","w2_11 -5.9531113125541e-06\n","w2_21 -0.002401656514351654\n","w2_02 0.001805707219248146\n","w2_12 4.464833484415552e-06\n","w2_22 0.0018012423857637306\n","w1_01 2.0784370290840247e-05\n","w1_11 2.0784370290840247e-05\n","w1_21 2.0784370290840247e-05\n","w1_02 3.117655543625889e-05\n","w1_12 3.117655543625889e-05\n","w1_22 3.117655543625889e-05\n"]}]},{"cell_type":"markdown","source":["b)"],"metadata":{"id":"Lud8dfZTBO6-"}},{"cell_type":"code","source":["class ThreeLayerNetwork:\n","    def __init__(self, input_size, hidden_size, output_size=1):\n","        self.W1 = np.random.randn(input_size, hidden_size)\n","        self.b1 = np.zeros(hidden_size)\n","        self.W2 = np.random.randn(hidden_size, hidden_size)\n","        self.b2 = np.zeros(hidden_size)\n","        self.W3 = np.random.randn(hidden_size, output_size)\n","        self.b3 = np.zeros(output_size)\n","\n","    def forward(self, X):\n","        z1 = X.dot(self.W1) + self.b1\n","        a1 = sigmoid(z1)\n","\n","        z2 = a1.dot(self.W2) + self.b2\n","        a2 = sigmoid(z2)\n","\n","        z3 = a2.dot(self.W3) + self.b3\n","        y = sigmoid(z3)\n","\n","        cache = {\n","            'X': X, 'z1': z1, 'a1': a1, 'z2': z2, 'a2': a2, 'z3': z3, 'y': y\n","        }\n","        return y, cache\n","\n","    def loss(self, X, y_true):\n","        y, cache = self.forward(X)\n","\n","        diff = (y_true.reshape(-1,1) - y)\n","        loss = 0.5 * np.mean(diff**2)\n","\n","        N = X.shape[0]\n","        dL_dy = (y - y_true.reshape(-1,1))\n","        dL_dz3 = dL_dy * sigmoid_prime(cache['z3'])\n","\n","        dW3 = cache['a2'].T.dot(dL_dz3) / N\n","        db3 = np.sum(dL_dz3, axis=0) / N\n","\n","        dL_da2 = dL_dz3.dot(self.W3.T)\n","        dL_dz2 = dL_da2 * sigmoid_prime(cache['z2'])\n","\n","        dW2 = cache['a1'].T.dot(dL_dz2) / N\n","        db2 = np.sum(dL_dz2, axis=0) / N\n","\n","        dL_da1 = dL_dz2.dot(self.W2.T)\n","        dL_dz1 = dL_da1 * sigmoid_prime(cache['z1'])\n","\n","        dW1 = cache['X'].T.dot(dL_dz1) / N\n","        db1 = np.sum(dL_dz1, axis=0) / N\n","\n","        grads = {\n","            'W1': dW1, 'b1': db1,\n","            'W2': dW2, 'b2': db2,\n","            'W3': dW3, 'b3': db3\n","        }\n","        return loss, grads\n","\n","    def update_params(self, grads, lr):\n","        self.W1 -= lr * grads['W1']\n","        self.b1 -= lr * grads['b1']\n","        self.W2 -= lr * grads['W2']\n","        self.b2 -= lr * grads['b2']\n","        self.W3 -= lr * grads['W3']\n","        self.b3 -= lr * grads['b3']\n","\n","    def predict(self, X):\n","        y_pred, _ = self.forward(X)\n","        return np.where(y_pred >= 0.5, 1, -1).flatten()"],"metadata":{"id":"Ep7UCghvAYT_","executionInfo":{"status":"ok","timestamp":1734227861021,"user_tz":420,"elapsed":80,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def compute_error(y_pred, y_true):\n","    return np.mean(y_pred != y_true)"],"metadata":{"id":"1Fzm3ETRB4pP","executionInfo":{"status":"ok","timestamp":1734227865579,"user_tz":420,"elapsed":104,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def train_network(X_train, y_train, X_test, y_test, hidden_size, gamma0, d, epochs=10, batch_size=32):\n","    N = X_train.shape[0]\n","    net = ThreeLayerNetwork(X_train.shape[1], hidden_size)\n","\n","    updates = 0\n","    train_loss_history = []\n","\n","    for epoch in range(epochs):\n","        perm = np.random.permutation(N)\n","        X_train = X_train[perm]\n","        y_train = y_train[perm]\n","\n","        for i in range(0, N, batch_size):\n","            X_batch = X_train[i:i+batch_size]\n","            y_batch = y_train[i:i+batch_size]\n","\n","            loss, grads = net.loss(X_batch, y_batch)\n","            lr = gamma0 / (1 + (gamma0/d)*updates)\n","            net.update_params(grads, lr)\n","\n","            updates += 1\n","            train_loss_history.append(loss)\n","\n","        train_pred = net.predict(X_train)\n","        test_pred = net.predict(X_test)\n","        train_err = compute_error(train_pred, y_train)\n","        test_err = compute_error(test_pred, y_test)\n","        print(f\"Epoch {epoch+1}, Updates {updates}, Loss {loss:.4f}, Train Err: {train_err:.4f}, Test Err: {test_err:.4f}\")\n","\n","    return net, train_loss_history"],"metadata":{"id":"IfxndgDTCAl9","executionInfo":{"status":"ok","timestamp":1734227866814,"user_tz":420,"elapsed":99,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["gamma0 = 0.1\n","d = 1000\n","hidden_sizes = [5, 10, 25, 50, 100]\n","for h in hidden_sizes:\n","    print(f\"Training with hidden size {h}\")\n","    net, loss_hist = train_network(X_train, y_train, X_test, y_test, h, gamma0, d, epochs=20, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBoSxME7B5Q_","executionInfo":{"status":"ok","timestamp":1734227901714,"user_tz":420,"elapsed":2648,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"2df0d6ab-3937-460c-8b9a-91db13716317"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with hidden size 5\n","Epoch 1, Updates 28, Loss 0.4332, Train Err: 0.2890, Test Err: 0.2620\n","Epoch 2, Updates 56, Loss 0.6024, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 3, Updates 84, Loss 0.5264, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 4, Updates 112, Loss 0.5560, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 5, Updates 140, Loss 0.5637, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 6, Updates 168, Loss 0.4952, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 7, Updates 196, Loss 0.4295, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 8, Updates 224, Loss 0.4038, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 9, Updates 252, Loss 0.4461, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 10, Updates 280, Loss 0.4826, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 11, Updates 308, Loss 0.5524, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 12, Updates 336, Loss 0.4201, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 13, Updates 364, Loss 0.4577, Train Err: 0.4461, Test Err: 0.4420\n","Epoch 14, Updates 392, Loss 0.3622, Train Err: 0.4278, Test Err: 0.4140\n","Epoch 15, Updates 420, Loss 0.3959, Train Err: 0.3830, Test Err: 0.3780\n","Epoch 16, Updates 448, Loss 0.4586, Train Err: 0.3647, Test Err: 0.3500\n","Epoch 17, Updates 476, Loss 0.4375, Train Err: 0.3509, Test Err: 0.3340\n","Epoch 18, Updates 504, Loss 0.3041, Train Err: 0.3291, Test Err: 0.3080\n","Epoch 19, Updates 532, Loss 0.4534, Train Err: 0.3154, Test Err: 0.2940\n","Epoch 20, Updates 560, Loss 0.3694, Train Err: 0.2798, Test Err: 0.2460\n","Training with hidden size 10\n","Epoch 1, Updates 28, Loss 0.5525, Train Err: 0.3911, Test Err: 0.3760\n","Epoch 2, Updates 56, Loss 0.5008, Train Err: 0.3704, Test Err: 0.3540\n","Epoch 3, Updates 84, Loss 0.4708, Train Err: 0.3314, Test Err: 0.3040\n","Epoch 4, Updates 112, Loss 0.3877, Train Err: 0.2924, Test Err: 0.2640\n","Epoch 5, Updates 140, Loss 0.3186, Train Err: 0.2133, Test Err: 0.1740\n","Epoch 6, Updates 168, Loss 0.3104, Train Err: 0.1709, Test Err: 0.1480\n","Epoch 7, Updates 196, Loss 0.5386, Train Err: 0.1537, Test Err: 0.1420\n","Epoch 8, Updates 224, Loss 0.5540, Train Err: 0.1399, Test Err: 0.1320\n","Epoch 9, Updates 252, Loss 0.2353, Train Err: 0.1193, Test Err: 0.1160\n","Epoch 10, Updates 280, Loss 0.3450, Train Err: 0.1044, Test Err: 0.1060\n","Epoch 11, Updates 308, Loss 0.4728, Train Err: 0.0975, Test Err: 0.1020\n","Epoch 12, Updates 336, Loss 0.4677, Train Err: 0.0872, Test Err: 0.0960\n","Epoch 13, Updates 364, Loss 0.4421, Train Err: 0.0826, Test Err: 0.0980\n","Epoch 14, Updates 392, Loss 0.4815, Train Err: 0.0734, Test Err: 0.0920\n","Epoch 15, Updates 420, Loss 0.4188, Train Err: 0.0654, Test Err: 0.0840\n","Epoch 16, Updates 448, Loss 0.2485, Train Err: 0.0596, Test Err: 0.0740\n","Epoch 17, Updates 476, Loss 0.4624, Train Err: 0.0585, Test Err: 0.0700\n","Epoch 18, Updates 504, Loss 0.3117, Train Err: 0.0505, Test Err: 0.0580\n","Epoch 19, Updates 532, Loss 0.2717, Train Err: 0.0482, Test Err: 0.0580\n","Epoch 20, Updates 560, Loss 0.1541, Train Err: 0.0470, Test Err: 0.0560\n","Training with hidden size 25\n","Epoch 1, Updates 28, Loss 0.3144, Train Err: 0.3131, Test Err: 0.3180\n","Epoch 2, Updates 56, Loss 0.2153, Train Err: 0.2844, Test Err: 0.2880\n","Epoch 3, Updates 84, Loss 0.4546, Train Err: 0.2466, Test Err: 0.2480\n","Epoch 4, Updates 112, Loss 0.2722, Train Err: 0.1239, Test Err: 0.1340\n","Epoch 5, Updates 140, Loss 0.4183, Train Err: 0.0906, Test Err: 0.0980\n","Epoch 6, Updates 168, Loss 0.1928, Train Err: 0.0734, Test Err: 0.0860\n","Epoch 7, Updates 196, Loss 0.2858, Train Err: 0.0654, Test Err: 0.0800\n","Epoch 8, Updates 224, Loss 0.2422, Train Err: 0.0596, Test Err: 0.0800\n","Epoch 9, Updates 252, Loss 0.3843, Train Err: 0.0550, Test Err: 0.0780\n","Epoch 10, Updates 280, Loss 0.3926, Train Err: 0.0470, Test Err: 0.0720\n","Epoch 11, Updates 308, Loss 0.2612, Train Err: 0.0447, Test Err: 0.0720\n","Epoch 12, Updates 336, Loss 0.2774, Train Err: 0.0401, Test Err: 0.0660\n","Epoch 13, Updates 364, Loss 0.2154, Train Err: 0.0356, Test Err: 0.0600\n","Epoch 14, Updates 392, Loss 0.3286, Train Err: 0.0378, Test Err: 0.0600\n","Epoch 15, Updates 420, Loss 0.3247, Train Err: 0.0344, Test Err: 0.0540\n","Epoch 16, Updates 448, Loss 0.1956, Train Err: 0.0344, Test Err: 0.0540\n","Epoch 17, Updates 476, Loss 0.4339, Train Err: 0.0321, Test Err: 0.0520\n","Epoch 18, Updates 504, Loss 0.3264, Train Err: 0.0321, Test Err: 0.0520\n","Epoch 19, Updates 532, Loss 0.5146, Train Err: 0.0310, Test Err: 0.0460\n","Epoch 20, Updates 560, Loss 0.1959, Train Err: 0.0298, Test Err: 0.0440\n","Training with hidden size 50\n","Epoch 1, Updates 28, Loss 0.3664, Train Err: 0.3567, Test Err: 0.3720\n","Epoch 2, Updates 56, Loss 0.2978, Train Err: 0.3509, Test Err: 0.3620\n","Epoch 3, Updates 84, Loss 0.4140, Train Err: 0.3050, Test Err: 0.3080\n","Epoch 4, Updates 112, Loss 0.3562, Train Err: 0.2076, Test Err: 0.2160\n","Epoch 5, Updates 140, Loss 0.4449, Train Err: 0.0986, Test Err: 0.0980\n","Epoch 6, Updates 168, Loss 0.4181, Train Err: 0.0677, Test Err: 0.0740\n","Epoch 7, Updates 196, Loss 0.3699, Train Err: 0.0356, Test Err: 0.0560\n","Epoch 8, Updates 224, Loss 0.3174, Train Err: 0.0287, Test Err: 0.0440\n","Epoch 9, Updates 252, Loss 0.2683, Train Err: 0.0195, Test Err: 0.0200\n","Epoch 10, Updates 280, Loss 0.4199, Train Err: 0.0149, Test Err: 0.0220\n","Epoch 11, Updates 308, Loss 0.1980, Train Err: 0.0092, Test Err: 0.0180\n","Epoch 12, Updates 336, Loss 0.2974, Train Err: 0.0069, Test Err: 0.0100\n","Epoch 13, Updates 364, Loss 0.3940, Train Err: 0.0057, Test Err: 0.0100\n","Epoch 14, Updates 392, Loss 0.3337, Train Err: 0.0057, Test Err: 0.0060\n","Epoch 15, Updates 420, Loss 0.3240, Train Err: 0.0057, Test Err: 0.0060\n","Epoch 16, Updates 448, Loss 0.2573, Train Err: 0.0046, Test Err: 0.0060\n","Epoch 17, Updates 476, Loss 0.2563, Train Err: 0.0046, Test Err: 0.0060\n","Epoch 18, Updates 504, Loss 0.4112, Train Err: 0.0046, Test Err: 0.0060\n","Epoch 19, Updates 532, Loss 0.3806, Train Err: 0.0046, Test Err: 0.0060\n","Epoch 20, Updates 560, Loss 0.2545, Train Err: 0.0046, Test Err: 0.0060\n","Training with hidden size 100\n","Epoch 1, Updates 28, Loss 0.4216, Train Err: 0.4128, Test Err: 0.4260\n","Epoch 2, Updates 56, Loss 0.3368, Train Err: 0.3452, Test Err: 0.3540\n","Epoch 3, Updates 84, Loss 0.4552, Train Err: 0.2580, Test Err: 0.2720\n","Epoch 4, Updates 112, Loss 0.4003, Train Err: 0.2167, Test Err: 0.2320\n","Epoch 5, Updates 140, Loss 0.2701, Train Err: 0.0367, Test Err: 0.0420\n","Epoch 6, Updates 168, Loss 0.3899, Train Err: 0.0206, Test Err: 0.0180\n","Epoch 7, Updates 196, Loss 0.4504, Train Err: 0.0126, Test Err: 0.0120\n","Epoch 8, Updates 224, Loss 0.4031, Train Err: 0.0103, Test Err: 0.0100\n","Epoch 9, Updates 252, Loss 0.3856, Train Err: 0.0046, Test Err: 0.0080\n","Epoch 10, Updates 280, Loss 0.3276, Train Err: 0.0034, Test Err: 0.0060\n","Epoch 11, Updates 308, Loss 0.3203, Train Err: 0.0034, Test Err: 0.0060\n","Epoch 12, Updates 336, Loss 0.1898, Train Err: 0.0034, Test Err: 0.0040\n","Epoch 13, Updates 364, Loss 0.3194, Train Err: 0.0034, Test Err: 0.0040\n","Epoch 14, Updates 392, Loss 0.2634, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 15, Updates 420, Loss 0.3862, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 16, Updates 448, Loss 0.3206, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 17, Updates 476, Loss 0.3154, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 18, Updates 504, Loss 0.2545, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 19, Updates 532, Loss 0.2639, Train Err: 0.0023, Test Err: 0.0040\n","Epoch 20, Updates 560, Loss 0.2539, Train Err: 0.0023, Test Err: 0.0040\n"]}]},{"cell_type":"markdown","source":["c) After changing the weights to 0, it seemed as if the errors platued and this is probably because it stops learning."],"metadata":{"id":"MJvpsR54Db8J"}},{"cell_type":"markdown","source":["d)The neural network has lower test error than the SVM and better preformance but SVM is more stable."],"metadata":{"id":"Sj_I_LfdEC1z"}},{"cell_type":"markdown","source":["e) some credit to Deep Learning w/Anna Fariha assignments"],"metadata":{"id":"Mmh9RqRUGmXS"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)\n","\n","y_train_binary = torch.where(y_train == 1, torch.tensor(1.0), torch.tensor(0.0))\n","y_test_binary = torch.where(y_test == 1, torch.tensor(1.0), torch.tensor(0.0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9yyYQFwItuW","executionInfo":{"status":"ok","timestamp":1734229780428,"user_tz":420,"elapsed":59,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"e30153b6-733b-4a62-96ae-ba35b647d73e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-35-d0dbac6c34bf>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_train = torch.tensor(X_train, dtype=torch.float32)\n","<ipython-input-35-d0dbac6c34bf>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train = torch.tensor(y_train, dtype=torch.float32)\n","<ipython-input-35-d0dbac6c34bf>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_test = torch.tensor(X_test, dtype=torch.float32)\n","<ipython-input-35-d0dbac6c34bf>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_test = torch.tensor(y_test, dtype=torch.float32)\n"]}]},{"cell_type":"code","source":["def initialize_weights(m, activation='tanh'):\n","    if isinstance(m, nn.Linear):\n","        if activation == 'tanh':\n","            nn.init.xavier_normal_(m.weight)\n","        elif activation == 'relu':\n","            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n","        if m.bias is not None:\n","            nn.init.zeros_(m.bias)"],"metadata":{"id":"eJbSWmF7I7ks","executionInfo":{"status":"ok","timestamp":1734229611685,"user_tz":420,"elapsed":73,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def build_network(input_size, depth, width, activation='tanh'):\n","    layers = []\n","    layers.append(nn.Linear(input_size, width))\n","    if activation == 'tanh':\n","        layers.append(nn.Tanh())\n","    else:\n","        layers.append(nn.ReLU())\n","\n","    for _ in range(depth - 2):\n","        layers.append(nn.Linear(width, width))\n","        if activation == 'tanh':\n","            layers.append(nn.Tanh())\n","        else:\n","            layers.append(nn.ReLU())\n","\n","    layers.append(nn.Linear(width, 1))\n","\n","    model = nn.Sequential(*layers)\n","    model.apply(lambda m: initialize_weights(m, activation))\n","    return model"],"metadata":{"id":"tRBYZ2wsI94a","executionInfo":{"status":"ok","timestamp":1734229631292,"user_tz":420,"elapsed":93,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def compute_error(model, X, y):\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(X)\n","        pred = torch.sigmoid(logits)\n","        pred_labels = (pred >= 0.5).float()\n","        y_binary = torch.where(y == 1, torch.tensor(1.0, device=y.device), torch.tensor(0.0, device=y.device))\n","        error = (pred_labels.flatten() != y_binary).float().mean().item()\n","    return error\n"],"metadata":{"id":"rmzbJR52JEDf","executionInfo":{"status":"ok","timestamp":1734229727844,"user_tz":420,"elapsed":86,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def train_model(model, X_train, y_train, X_test, y_test, epochs=20, batch_size=32):\n","    y_train_binary = torch.where(y_train == 1, torch.tensor(1.0, device=y_train.device), torch.tensor(0.0, device=y_train.device))\n","    y_test_binary = torch.where(y_test == 1, torch.tensor(1.0, device=y_test.device), torch.tensor(0.0, device=y_test.device))\n","\n","    dataset = TensorDataset(X_train, y_train_binary)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        for X_batch, y_batch in loader:\n","            optimizer.zero_grad()\n","            logits = model(X_batch)\n","            loss = criterion(logits, y_batch.unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","    train_err = compute_error(model, X_train, y_train)\n","    test_err = compute_error(model, X_test, y_test)\n","    return train_err, test_err"],"metadata":{"id":"TajPybRZGNPT","executionInfo":{"status":"ok","timestamp":1734229678254,"user_tz":420,"elapsed":51,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["depths = [3, 5, 9]\n","widths = [5, 10, 25, 50, 100]\n","activations = ['tanh', 'relu']\n","\n","for activation in activations:\n","    print(f\"Activation: {activation}\")\n","    for depth in depths:\n","        for width in widths:\n","            model = build_network(input_size=X_train.shape[1], depth=depth, width=width, activation=activation)\n","            train_err, test_err = train_model(model, X_train, y_train, X_test, y_test, epochs=20, batch_size=32)\n","            print(f\"Depth: {depth}, Width: {width}, Train Err: {train_err:.4f}, Test Err: {test_err:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1y3nXKVJOOT","executionInfo":{"status":"ok","timestamp":1734229932672,"user_tz":420,"elapsed":53027,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"93d080ec-5b11-4ffa-b384-7cf2ab82ce3b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Activation: tanh\n","Depth: 3, Width: 5, Train Err: 0.0161, Test Err: 0.0160\n","Depth: 3, Width: 10, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 3, Width: 25, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 3, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 3, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 5, Width: 5, Train Err: 0.0000, Test Err: 0.0040\n","Depth: 5, Width: 10, Train Err: 0.0000, Test Err: 0.0020\n","Depth: 5, Width: 25, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 5, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 5, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 5, Train Err: 0.0000, Test Err: 0.0020\n","Depth: 9, Width: 10, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 25, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n","Activation: relu\n","Depth: 3, Width: 5, Train Err: 0.0654, Test Err: 0.0660\n","Depth: 3, Width: 10, Train Err: 0.0034, Test Err: 0.0060\n","Depth: 3, Width: 25, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 3, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 3, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 5, Width: 5, Train Err: 0.0023, Test Err: 0.0000\n","Depth: 5, Width: 10, Train Err: 0.0011, Test Err: 0.0000\n","Depth: 5, Width: 25, Train Err: 0.0000, Test Err: 0.0020\n","Depth: 5, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 5, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 5, Train Err: 0.1158, Test Err: 0.1000\n","Depth: 9, Width: 10, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 25, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 50, Train Err: 0.0000, Test Err: 0.0000\n","Depth: 9, Width: 100, Train Err: 0.0000, Test Err: 0.0000\n"]}]},{"cell_type":"markdown","source":["The super low or non existent values are super suspicous and I conclude I did this wrong."],"metadata":{"id":"5nBuaTDGKATb"}},{"cell_type":"markdown","source":["3.a)"],"metadata":{"id":"WyCYc5EvK7u2"}},{"cell_type":"code","source":[],"metadata":{"id":"xKmBEKUoK-hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile script.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyi8zQe6hQTU","executionInfo":{"status":"ok","timestamp":1734229966300,"user_tz":420,"elapsed":75,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"87ff29e6-e6f9-4280-96eb-1ab9efa4b657"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing script.sh\n"]}]},{"cell_type":"code","source":["%%writefile run.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjxaLLiehQ_B","executionInfo":{"status":"ok","timestamp":1734229970725,"user_tz":420,"elapsed":90,"user":{"displayName":"Samantha Roberts","userId":"09423478274316575340"}},"outputId":"8ef93b04-2ee7-40a2-90a2-defaa8d46f07"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing run.sh\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTpmbs1huU98lycXhm/dZY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}